{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh7BRWZq5UH2kL475jMZhh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezinneanne/farmeyeml/blob/new_branch/farmeyeimg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSDuVFzaUCQQ"
      },
      "outputs": [],
      "source": [
        "# Mounting Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf #importing tensorflow for deep learning functionality\n",
        "from tensorflow.keras import layers, models # Import the 'layers' and 'models' submodules from tensorflow.keras\n",
        "# 'layers' is used to build different types of neural network layers (e.g., Conv2D, Dense, etc.)\n",
        "# 'models' provides APIs to create and manage models (Sequential and Functional APIs)\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2 # Import the pre-trained MobileNetV2 model from keras.applications\n",
        "# MobileNetV2 is a lightweight deep convolutional neural network architecture for mobile and edge devices\n",
        "# It can be used as a feature extractor or a full model for transfer learning\n",
        "\n",
        "from sklearn.metrics import classification_report # to make classification report for evaluation\n",
        "import numpy as np # importing numpy for numerical operations\n",
        "\n",
        "from tensorflow.keras.models import Sequential  # Importing Sequential model for linear stacking of layers\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "Qyl7ZQk1YsHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== paths ====\n",
        "data_dir = pathlib.Path(\"/content/segmented\")\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "seed = 1337"
      ],
      "metadata": {
        "id": "Nelb1su6dbUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD DATASET AND SPLIT\n",
        "# Load training data from the dataset directory, with 80% for training\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,                 # Path to images\n",
        "    validation_split=0.15,     # 15% for validation\n",
        "    subset=\"training\",        # This is the training subset\n",
        "    seed=seed,                 # Seed for consistent split\n",
        "    image_size=img_size,  # Resize all images\n",
        "    batch_size=batch_size     # Number of images per batch\n",
        ")\n",
        "\n",
        "# Load validation data (remaining 15%)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.15,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Get class names and number of classes\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)"
      ],
      "metadata": {
        "id": "KBfy_mgZdf9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREFETCHING FOR PERFORMANCE\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Cache, shuffle, and prefetch training dataset for better performance\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Cache and prefetch validation dataset (no shuffling needed)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "lvtF7HNkfOyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== data augmentation ====\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomBrightness(factor=0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "SwP8Banff1wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== base model (transfer learning) ====\n",
        "# weights='imagenet' means the model is loaded with weights learned from training on the ImageNet dataset\n",
        "# input_shape specifies the shape of input images (height, width, 3 channels for RGB)\n",
        "# include_top=False excludes the fully connected layers at the top of the model (used for classification in ImageNet)\n",
        "base = tf.keras.applications.EfficientNetB0(\n",
        "    include_top=False, input_shape=img_size + (3,), weights=\"imagenet\"\n",
        ")\n",
        "base.trainable = False  # Freeze base model layers so its weights will not be updated during training\n",
        "\n",
        "# Build model on top of EfficientNetB0\n",
        "inputs = layers.Input(shape=img_size + (3,))\n",
        "x = data_augmentation(inputs)\n",
        "x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
        "x = base(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\"),\n",
        "    ReduceLROnPlateau(patience=2, factor=0.3, monitor=\"val_loss\"),\n",
        "    ModelCheckpoint(\"best_seg_model.h5\", save_best_only=True, monitor=\"val_accuracy\")\n",
        "]\n",
        "\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=15, callbacks=callbacks)\n",
        "\n",
        "# ==== unfreeze top layers for a short fine-tune====\n",
        "base.trainable = True\n",
        "for layer in base.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_ft = model.fit(train_ds, validation_data=val_ds, epochs=5, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "JXIOpfjOgcoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"plant_disease_classifier.keras\")"
      ],
      "metadata": {
        "id": "z84fLNmFhYUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation set\n",
        "val_loss, val_acc = model.evaluate(val_ds)\n",
        "print(f\"Validation accuracy: {val_acc:.3f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "import numpy as np, itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "for imgs, labels in val_ds:\n",
        "    preds = model.predict(imgs, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "agDhbcyuhf7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}