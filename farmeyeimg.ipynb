{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezinneanne/farmeyeml/blob/new_branch/farmeyeimg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "DA8TPF8PP5rJ",
        "outputId": "eac1fa9c-632e-49e5-d1a8-0cb7b7bb0356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSDuVFzaUCQQ",
        "outputId": "171ad7fe-5c7c-41e6-9c3f-5134a681031f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset unzipped.\n"
          ]
        }
      ],
      "source": [
        "# UNZIP DATASET\n",
        "import zipfile, os\n",
        "\n",
        "# Define the path to the zipped dataset and where to extract it\n",
        "zip_path = '/content/drive/MyDrive/segmented.zip'\n",
        "extract_path = '/content/segmented'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Unzip the dataset to the extraction path\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset unzipped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qyl7ZQk1YsHL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf #importing tensorflow for deep learning functionality\n",
        "from tensorflow.keras import layers, models # Import the 'layers' and 'models' submodules from tensorflow.keras\n",
        "# 'layers' is used to build different types of neural network layers (e.g., Conv2D, Dense, etc.)\n",
        "# 'models' provides APIs to create and manage models (Sequential and Functional APIs)\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2 # Import the pre-trained MobileNetV2 model from keras.applications\n",
        "# MobileNetV2 is a lightweight deep convolutional neural network architecture for mobile and edge devices\n",
        "# It can be used as a feature extractor or a full model for transfer learning\n",
        "\n",
        "from sklearn.metrics import classification_report # to make classification report for evaluation\n",
        "import numpy as np # importing numpy for numerical operations\n",
        "\n",
        "from tensorflow.keras.models import Sequential  # Importing Sequential model for linear stacking of layers\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nelb1su6dbUx"
      },
      "outputs": [],
      "source": [
        "# ==== paths ====\n",
        "data_dir = pathlib.Path(\"/content/segmented/segmented\")\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "seed = 1337"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List subfolders (classes) inside segmented\n",
        "print(\"\\nSubfolders found (classes):\")\n",
        "for item in data_dir.iterdir():\n",
        "    if item.is_dir():\n",
        "        print(\" -\", item.name)\n",
        "\n",
        "# List a few files in the first subfolder\n",
        "first_class = next(data_dir.iterdir())\n",
        "if first_class.is_dir():\n",
        "    print(f\"\\nSample files in '{first_class.name}':\")\n",
        "    for file in list(first_class.glob(\"*\"))[:5]:  # show 5 images\n",
        "        print(\"   \", file.name)"
      ],
      "metadata": {
        "id": "7ZR9iJAjUyB1",
        "outputId": "0674457e-f9ab-46f0-bfba-b63b5d875e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Subfolders found (classes):\n",
            " - Squash___Powdery_mildew\n",
            " - Tomato___healthy\n",
            " - Corn_(maize)___healthy\n",
            " - Corn_(maize)___Common_rust_\n",
            " - Cherry_(including_sour)___healthy\n",
            " - Cherry_(including_sour)___Powdery_mildew\n",
            " - Strawberry___Leaf_scorch\n",
            " - Blueberry___healthy\n",
            " - Grape___healthy\n",
            " - Strawberry___healthy\n",
            " - Pepper,_bell___Bacterial_spot\n",
            " - Tomato___Bacterial_spot\n",
            " - Tomato___Spider_mites Two-spotted_spider_mite\n",
            " - Orange___Haunglongbing_(Citrus_greening)\n",
            " - Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            " - Grape___Esca_(Black_Measles)\n",
            " - Tomato___Target_Spot\n",
            " - Potato___Late_blight\n",
            " - Soybean___healthy\n",
            " - Grape___Black_rot\n",
            " - Corn_(maize)___Northern_Leaf_Blight\n",
            " - Raspberry___healthy\n",
            " - Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            " - Potato___Early_blight\n",
            " - Apple___Black_rot\n",
            " - Apple___Apple_scab\n",
            " - Tomato___Late_blight\n",
            " - Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            " - Peach___Bacterial_spot\n",
            " - Tomato___Leaf_Mold\n",
            " - Peach___healthy\n",
            " - Apple___Cedar_apple_rust\n",
            " - Tomato___Septoria_leaf_spot\n",
            " - Tomato___Tomato_mosaic_virus\n",
            " - Apple___healthy\n",
            " - Potato___healthy\n",
            " - Tomato___Early_blight\n",
            " - Pepper,_bell___healthy\n",
            "\n",
            "Sample files in 'Squash___Powdery_mildew':\n",
            "    54552d89-5ddd-4a3c-9ccd-3f12e9233792___UMD_Powd.M 0600_final_masked.jpg\n",
            "    0e025cbc-150b-4d26-8e94-8190c3b9ee66___MD_Powd.M 0653_final_masked.jpg\n",
            "    141ff102-df00-47e4-81fe-e217938d28b3___UMD_Powd.M 0155_final_masked.jpg\n",
            "    50fd0706-d009-415f-af6a-e5210fd3654d___UMD_Powd.M 0321_final_masked.jpg\n",
            "    1a8a668d-1c6a-4fec-b84f-3126adc24687___MD_Powd.M 0878_final_masked.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KBfy_mgZdf9D",
        "outputId": "6a3edbd1-a2b3-44bb-a940-c975087eb999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 54306 files belonging to 38 classes.\n",
            "Using 46161 files for training.\n",
            "Found 54306 files belonging to 38 classes.\n",
            "Using 8145 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# LOAD DATASET AND SPLIT\n",
        "# Load training data from the dataset directory, with 80% for training\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,                 # Path to images\n",
        "    validation_split=0.15,     # 15% for validation\n",
        "    subset=\"training\",        # This is the training subset\n",
        "    seed=seed,                 # Seed for consistent split\n",
        "    image_size=img_size,  # Resize all images\n",
        "    batch_size=batch_size     # Number of images per batch\n",
        ")\n",
        "\n",
        "# Load validation data (remaining 15%)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.15,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Get class names and number of classes\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lvtF7HNkfOyZ"
      },
      "outputs": [],
      "source": [
        "# PREFETCHING FOR PERFORMANCE\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Cache, shuffle, and prefetch training dataset for better performance\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Cache and prefetch validation dataset (no shuffling needed)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SwP8Banff1wJ"
      },
      "outputs": [],
      "source": [
        "# ==== data augmentation ====\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomBrightness(factor=0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JXIOpfjOgcoi",
        "outputId": "93af985a-4548-4960-ecf6-4d0aaf28a282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2955251915.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# include_top=False excludes the fully connected layers at the top of the model (used for classification in ImageNet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m base = tf.keras.applications.MobileNetV2(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "# ==== base model (transfer learning) ====\n",
        "# weights='imagenet' means the model is loaded with weights learned from training on the ImageNet dataset\n",
        "# input_shape specifies the shape of input images (height, width, 3 channels for RGB)\n",
        "# include_top=False excludes the fully connected layers at the top of the model (used for classification in ImageNet)\n",
        "\n",
        "base = tf.keras.applications.MobileNetV2(\n",
        "    include_top=False, input_shape=img_size + (3,), weights=\"imagenet\"\n",
        ")\n",
        "base.trainable = False  # Freeze base model layers so its weights will not be updated during training\n",
        "\n",
        "# Build model on top of MobileNetV2\n",
        "inputs = layers.Input(shape=img_size + (3,))\n",
        "x = data_augmentation(inputs)\n",
        "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
        "x = base(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\"),\n",
        "    ReduceLROnPlateau(patience=2, factor=0.3, monitor=\"val_loss\"),\n",
        "    ModelCheckpoint(\"best_seg_model.h5\", save_best_only=True, monitor=\"val_accuracy\")\n",
        "]\n",
        "\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=12, callbacks=callbacks)\n",
        "\n",
        "# ==== unfreeze top layers for a short fine-tune====\n",
        "base.trainable = True\n",
        "for layer in base.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_ft = model.fit(train_ds, validation_data=val_ds, epochs=5, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z84fLNmFhYUP"
      },
      "outputs": [],
      "source": [
        "model.save(\"plant_disease_classifier.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agDhbcyuhf7D"
      },
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "val_loss, val_acc = model.evaluate(val_ds)\n",
        "print(f\"Validation accuracy: {val_acc:.3f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "import numpy as np, itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "for imgs, labels in val_ds:\n",
        "    preds = model.predict(imgs, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}