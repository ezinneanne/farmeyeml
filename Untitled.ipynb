{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8d51dd-8a35-406d-933b-e777384af872",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTensorFlow version:\u001b[39m\u001b[33m\"\u001b[39m, tf.__version__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[39m\n\u001b[32m     86\u001b[39m     sys.setdlopenflags(_default_dlopen_flags)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     89\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback.format_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     90\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     92\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m     93\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIf you need help, create an issue \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     94\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     95\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mand include the entire stack trace above this error message.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Traceback (most recent call last):\n  File \"C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03edd40-683a-4866-9fcd-9582ccd90183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(\"C:/Users/DELL/OneDrive/Desktop/myworkz/farmeyeml/segmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b406df23-8dfc-430c-ae1a-e5f839e5af31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: C:\\Users\\DELL\\OneDrive\\Desktop\\myworkz\\farmeyeml\\segmented\n",
      "\n",
      "Subfolders found (classes):\n",
      " - Apple___Apple_scab\n",
      " - Apple___Black_rot\n",
      " - Apple___Cedar_apple_rust\n",
      " - Apple___healthy\n",
      " - Blueberry___healthy\n",
      " - Cherry_(including_sour)___healthy\n",
      " - Cherry_(including_sour)___Powdery_mildew\n",
      " - Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      " - Corn_(maize)___Common_rust_\n",
      " - Corn_(maize)___healthy\n",
      " - Corn_(maize)___Northern_Leaf_Blight\n",
      " - Grape___Black_rot\n",
      " - Grape___Esca_(Black_Measles)\n",
      " - Grape___healthy\n",
      " - Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      " - Orange___Haunglongbing_(Citrus_greening)\n",
      " - Peach___Bacterial_spot\n",
      " - Peach___healthy\n",
      " - Pepper,_bell___Bacterial_spot\n",
      " - Pepper,_bell___healthy\n",
      " - Potato___Early_blight\n",
      " - Potato___healthy\n",
      " - Potato___Late_blight\n",
      " - Raspberry___healthy\n",
      " - Soybean___healthy\n",
      " - Squash___Powdery_mildew\n",
      " - Strawberry___healthy\n",
      " - Strawberry___Leaf_scorch\n",
      " - Tomato___Bacterial_spot\n",
      " - Tomato___Early_blight\n",
      " - Tomato___healthy\n",
      " - Tomato___Late_blight\n",
      " - Tomato___Leaf_Mold\n",
      " - Tomato___Septoria_leaf_spot\n",
      " - Tomato___Spider_mites Two-spotted_spider_mite\n",
      " - Tomato___Target_Spot\n",
      " - Tomato___Tomato_mosaic_virus\n",
      " - Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "\n",
      "Sample files in 'Apple___Apple_scab':\n",
      "    00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335_final_masked.jpg\n",
      "    01a66316-0e98-4d3b-a56f-d78752cd043f___FREC_Scab 3003_final_masked.jpg\n",
      "    01f3deaa-6143-4b6c-9c22-620a46d8be04___FREC_Scab 3112_final_masked.jpg\n",
      "    0208f4eb-45a4-4399-904e-989ac2c6257c___FREC_Scab 3037_final_masked.jpg\n",
      "    023123cb-7b69-4c9f-a521-766d7c8543bb___FREC_Scab 3487_final_masked.jpg\n"
     ]
    }
   ],
   "source": [
    "# Print absolute path to confirm\n",
    "print(\"Dataset directory:\", data_dir.resolve())\n",
    "\n",
    "# List subfolders (classes) inside segmented\n",
    "print(\"\\nSubfolders found (classes):\")\n",
    "for item in data_dir.iterdir():\n",
    "    if item.is_dir():\n",
    "        print(\" -\", item.name)\n",
    "\n",
    "# List a few files in the first subfolder\n",
    "first_class = next(data_dir.iterdir())\n",
    "if first_class.is_dir():\n",
    "    print(f\"\\nSample files in '{first_class.name}':\")\n",
    "    for file in list(first_class.glob(\"*\"))[:5]:  # show 5 images\n",
    "        print(\"   \", file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe8d172a-3b07-4f83-ab1b-935e08924368",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0846acf-966d-41e3-ad5b-d0df30f21b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54306 files belonging to 38 classes.\n",
      "Using 46161 files for training.\n",
      "Found 54306 files belonging to 38 classes.\n",
      "Using 8145 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATASET AND SPLIT\n",
    "# Load training data from the dataset directory, with 80% for training\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,                 # Path to images\n",
    "    validation_split=0.15,     # 15% for validation\n",
    "    subset=\"training\",        # This is the training subset\n",
    "    seed=seed,                 # Seed for consistent split\n",
    "    image_size=img_size,  # Resize all images\n",
    "    batch_size=batch_size     # Number of images per batch\n",
    ")\n",
    "\n",
    "# Load validation data (remaining 15%)\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.15,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Get class names and number of classes\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a9ae59-7c73-40b4-98ee-31acfd531f09",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# PREFETCHING FOR PERFORMANCE\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m AUTOTUNE = \u001b[43mtf\u001b[49m.data.AUTOTUNE\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Cache, shuffle, and prefetch training dataset for better performance\u001b[39;00m\n\u001b[32m      5\u001b[39m train_ds = train_ds.cache().shuffle(\u001b[32m1000\u001b[39m).prefetch(buffer_size=AUTOTUNE)\n",
      "\u001b[31mNameError\u001b[39m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# PREFETCHING FOR PERFORMANCE\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Cache, shuffle, and prefetch training dataset for better performance\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Cache and prefetch validation dataset (no shuffling needed)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35158e38-c94e-4786-bcb4-d528c222768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models # Import the 'layers' and 'models' submodules from tensorflow.keras\n",
    "# 'layers' is used to build different types of neural network layers (e.g., Conv2D, Dense, etc.)\n",
    "# 'models' provides APIs to create and manage models (Sequential and Functional APIs)\n",
    "\n",
    "import numpy as np # importing numpy for numerical operations\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # Importing Sequential model for linear stacking of layers\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192e8929-8a80-47c7-9552-1edba618e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\tfenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== data augmentation ====\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomBrightness(factor=0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23fb010-51e2-4c30-931d-10bb992a1466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\tfenv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 500s 30us/step\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\tfenv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\tfenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 158/1443 [==>...........................] - ETA: 20:44 - loss: 1.9312 - accuracy: 0.5322"
     ]
    }
   ],
   "source": [
    "# ==== base model (transfer learning) ====\n",
    "# weights='imagenet' means the model is loaded with weights learned from training on the ImageNet dataset\n",
    "# input_shape specifies the shape of input images (height, width, 3 channels for RGB)\n",
    "# include_top=False excludes the fully connected layers at the top of the model (used for classification in ImageNet)\n",
    "base = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False, input_shape=img_size + (3,), weights=\"imagenet\"\n",
    ")\n",
    "base.trainable = False  # Freeze base model layers so its weights will not be updated during training\n",
    "\n",
    "# Build model on top of EfficientNetB0\n",
    "inputs = layers.Input(shape=img_size + (3,))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_accuracy\"),\n",
    "    ReduceLROnPlateau(patience=2, factor=0.3, monitor=\"val_loss\"),\n",
    "    ModelCheckpoint(\"best_seg_model.h5\", save_best_only=True, monitor=\"val_accuracy\")\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=15, callbacks=callbacks)\n",
    "\n",
    "# ==== unfreeze top layers for a short fine-tune====\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-40]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_ft = model.fit(train_ds, validation_data=val_ds, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36172485-cf05-4e7c-8734-1984fbbdea7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c40fb-8843-460a-95fe-9f7c6baf302a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
